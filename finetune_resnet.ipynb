{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To finetune the Resnet model, we first generate adversarial training images and adversarial validation images by the following commands:\n",
    "```\n",
    "python launch_resnet_attack.py --batch_num 20 --batch_size 100 --results 'adv_train_images'\n",
    "python launch_resnet_attack.py --batch_num 20 --batch_size 100 --results 'adv_val_images' --seed 0\n",
    "```\n",
    "The params are all default.\n",
    "Then we use `adv_train_images` to train the Resnet model and save it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Loading data...\n",
      "===Launching PGD attack on 20 batches of data===\n",
      "Attack configs: eps = 0.03137254901960784, alpha = 0.00784313725490196, steps = 20, batch size = 100\n",
      "100%|███████████████████████████████████████████| 20/20 [00:49<00:00,  2.49s/it]\n",
      "Accuracy on original images: 92.7%\n",
      "Accuracy on adversarial images: 2.0%\n",
      "Loading model...\n",
      "Loading data...\n",
      "===Launching PGD attack on 20 batches of data===\n",
      "Attack configs: eps = 0.03137254901960784, alpha = 0.00784313725490196, steps = 20, batch size = 100\n",
      "100%|███████████████████████████████████████████| 20/20 [00:49<00:00,  2.47s/it]\n",
      "Accuracy on original images: 91.5%\n",
      "Accuracy on adversarial images: 1.9%\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "!python launch_resnet_attack.py --batch_num 20 --batch_size 100 --results 'adv_train_images'\n",
    "!python launch_resnet_attack.py --batch_num 20 --batch_size 100 --results 'adv_val_images' --seed 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 4.3008\n",
      "Epoch [2/10], Loss: 1.4592\n",
      "Epoch [3/10], Loss: 0.8949\n",
      "Epoch [4/10], Loss: 0.6399\n",
      "Epoch [5/10], Loss: 0.4656\n",
      "Epoch [6/10], Loss: 0.3578\n",
      "Epoch [7/10], Loss: 0.2765\n",
      "Epoch [8/10], Loss: 0.2294\n",
      "Epoch [9/10], Loss: 0.1843\n",
      "Epoch [10/10], Loss: 0.1558\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "ADV_TRAIN_PATH = './results/adv_train_images'\n",
    "BATCH_SIZE = 100\n",
    "BATCH_NUM = 20\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "checkpoint = torch.load(ADV_TRAIN_PATH)\n",
    "adv_images = checkpoint['adv_images']\n",
    "labels = checkpoint['labels']\n",
    "\n",
    "dataset = TensorDataset(adv_images, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "weights = ResNet50_Weights.DEFAULT\n",
    "model = resnet50(weights=weights)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}')\n",
    "\n",
    "torch.save(model.state_dict(), 'results/resnet50_finetuned.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the finetuned model and use validation images to test it.\n",
    "\n",
    "The accuracy on adversarial validation images reaches 72.90%, much higher than the model without finetuned (1.9%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on adversarial validation images: 72.89999999999999%\n"
     ]
    }
   ],
   "source": [
    "model = resnet50(pretrained=False)\n",
    "model.load_state_dict(torch.load('results/resnet50_finetuned.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "ADV_VAL_PATH = './results/adv_val_images'\n",
    "BATCH_SIZE = 100\n",
    "BATCH_NUM = 20\n",
    "\n",
    "checkpoint = torch.load(ADV_VAL_PATH)\n",
    "val_images = checkpoint['adv_images']\n",
    "labels = checkpoint['labels']\n",
    "\n",
    "dataset = TensorDataset(val_images, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for inputs, labels in dataloader:\n",
    "  inputs, labels = inputs.to(device), labels.to(device)\n",
    "  with torch.no_grad():\n",
    "    outputs = model(inputs).softmax(1)\n",
    "    predictions = outputs.argmax(dim=1)\n",
    "  correct += torch.sum(predictions == labels).item()\n",
    "  total += len(labels)\n",
    "\n",
    "\n",
    "acc = correct / total\n",
    "print(f\"Accuracy on adversarial validation images: {acc * 100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
